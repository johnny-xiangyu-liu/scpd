{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22b1529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision as tv\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from torchvision import tv_tensors  # we'll describe this a bit later, bare with us\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "from pathlib import Path\n",
    "\n",
    "from torchview import draw_graph\n",
    "from pathlib import Path\n",
    "\n",
    "import constants\n",
    "import dataset\n",
    "import util\n",
    "import json\n",
    "import pandas as pd\n",
    "import models \n",
    "from models import VQANet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import traceback\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():      \n",
    "    device = 'mps'                         \n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "\n",
    "device = torch.device('cpu')\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ec1ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f0ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show(imgs):\n",
    "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = T.ToPILImage()(img.to('cpu'))\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8878aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(constants.CAPTION_TRAIN, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "#     print(data.keys())\n",
    "#     print(data[\"annotations\"][0])\n",
    "\n",
    "# with open(constants.VQA_OPEN_ENDED_QUESTION_TRAIN, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "#     print(data.keys())\n",
    "#     print(data[\"questions\"][0])\n",
    "\n",
    "# with open(constants.VQA_OPEN_ENDED_ANSWER_TRAIN, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "#     print(data.keys())\n",
    "#     print(data[\"annotations\"][0])\n",
    "    \n",
    "# with open(constants.CAPTION_VAL, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "#     print(data.keys())\n",
    "\n",
    "# with open(constants.VQA_OPEN_ENDED_QUESTION_VAL, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "#     print(data.keys())\n",
    "\n",
    "# with open(constants.VQA_OPEN_ENDED_ANSWER_VAL, 'r') as f:\n",
    "#     data = json.load(f)\n",
    "#     print(data.keys())\n",
    "\n",
    "#dataset.load(constants.VQA_OPEN_ENDED_QUESTION_TRAIN, ['image_id', 'id', 'caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9849a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/Users/xiangyuliu/sources/fiftyone_dataset_zoo/coco-2017/train' if necessary\n",
      "Found annotations at '/Users/xiangyuliu/sources/fiftyone_dataset_zoo/coco-2017/raw/instances_train2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'coco-2017-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      "Downloading split 'validation' to '/Users/xiangyuliu/sources/fiftyone_dataset_zoo/coco-2017/validation' if necessary\n",
      "Found annotations at '/Users/xiangyuliu/sources/fiftyone_dataset_zoo/coco-2017/raw/instances_val2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'validation' is sufficient\n",
      "Loading existing dataset 'coco-2017-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      "Downloading split 'test' to '/Users/xiangyuliu/sources/fiftyone_dataset_zoo/coco-2017/test' if necessary\n",
      "Found test info at '/Users/xiangyuliu/sources/fiftyone_dataset_zoo/coco-2017/raw/image_info_test2017.json'\n",
      "Images already downloaded\n",
      "Existing download of split 'test' is sufficient\n",
      "Loading existing dataset 'coco-2017-test'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    }
   ],
   "source": [
    "train = dataset.Coco()\n",
    "val = dataset.Coco(\"validation\")\n",
    "test = dataset.Coco(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc496dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118287\n",
      "591753\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(train.captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b029c00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False: # debug\n",
    "    img = train.__getitem__(1)\n",
    "    print(img)\n",
    "    print(img.image_id)\n",
    "    print(img.image_path)\n",
    "\n",
    "    print(\">>>>\")\n",
    "    print(img.captions())\n",
    "\n",
    "    print(\">>>>\")\n",
    "    print(img.qa())\n",
    "    print(\"shape\", img.image_tensor().shape)\n",
    "\n",
    "    show([img.image_tensor()])\n",
    "\n",
    "#plt.imshow(  img.image_tensor().permute(1, 2, 0)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037170fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer  = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "# Add the Q and A token as special token\n",
    "tokenizer.add_special_tokens(constants.QA_TOKEN_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de3b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagedata import get_image\n",
    "\n",
    "def path_to_image(paths, device):\n",
    "    result = []\n",
    "    for p in paths:\n",
    "        result.append(get_image(path, device))\n",
    "    image = torch.stack(result, dim = 0).to(device)\n",
    "    print(\"image shape\", image.shape)\n",
    "    return image\n",
    "    \n",
    "def collate_fn2(batch):\n",
    "    result = {}\n",
    "    \n",
    "    result['image_ids'] = []\n",
    "    result['image_paths'] = []\n",
    "    result['c2i'] = [] # index for images for a given caption. same len as 'caption'\n",
    "    result['qa2i'] = [] # index of corresponding image for a given qa. same len as 'qa'\n",
    "    result['q_id'] = [] # id of the questions 'qa'\n",
    "    \n",
    "    \n",
    "    target  = [] # the corresponding target for the qa.\n",
    "    raw_captions = []  # plain text \n",
    "    raw_qa = []   # plain text\n",
    "    raw_qids = []   # question ids\n",
    "    for idx, data in enumerate(batch):\n",
    "        result['image_ids'].append(data.image_id)\n",
    "        result['image_paths'].append(data.image_path)\n",
    "        caption_list = data.captions()\n",
    "        if caption_list is not None:\n",
    "            raw_captions += caption_list\n",
    "            for c in range(len(caption_list)):\n",
    "                result['c2i'].append(idx)\n",
    "        \n",
    "        qa_list = data.qa()\n",
    "        q_id_list = data.qids()\n",
    "        if qa_list is not None:\n",
    "            raw_qa += qa_list\n",
    "            raw_qids += q_id_list\n",
    "            for c in range(len(qa_list)):\n",
    "                result['qa2i'].append(idx)\n",
    "    #print(\"raw_cap\", len(raw_captions))\n",
    "    #print(\"raw_qa\", len(raw_qa))\n",
    "    \n",
    "    result['raw_cap'] = raw_captions\n",
    "    result['captions'] = None if len(raw_captions) == 0 else \\\n",
    "                                tokenizer(raw_captions, padding=True , return_tensors=\"pt\").to(device)\n",
    "    result['raw_qa'] = raw_qa\n",
    "    result['qids'] = raw_qids\n",
    "    if len(raw_qa) != 0:\n",
    "#        print(\"raw_qa:\", raw_qa)\n",
    "        result['qa'] =  tokenizer(raw_qa, padding=True , return_tensors=\"pt\")['input_ids'].to(device, dtype=torch.int64)\n",
    "        end_padding = torch.broadcast_to(torch.zeros(1), (result['qa'].shape[0], 1)).to(device, dtype=torch.int64)\n",
    "        #print(end_padding.shape)\n",
    "        # return a shape {seq, batch}\n",
    "        target = torch.column_stack((result['qa'][:, 1:], end_padding)).transpose(0, 1)\n",
    "    else:\n",
    "        result['qa'] = None\n",
    "        target = None\n",
    "    return result, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c7465ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 5\n",
    "fn = collate_fn2 \n",
    "shuffle = False  # True\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size, shuffle=shuffle, collate_fn=fn)\n",
    "val_dataloader = DataLoader(val, batch_size=batch_size, shuffle=shuffle, collate_fn=fn)\n",
    "test_dataloader = DataLoader(test, batch_size=batch_size, shuffle=shuffle, collate_fn=fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba784bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check(dataloader, size=5):\n",
    "    it = iter(dataloader)\n",
    "    for _ in range(size):\n",
    "        x, target= next(it)\n",
    "        print(x)\n",
    "        show(x[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3763a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spot_check(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea280f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spot_check(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "545e9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_fn = nn.CrossEntropyLoss( reduction='none')\n",
    "cos_fn = nn.CosineSimilarity(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1d7d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# out = model(x, device)\n",
    "# image_embedding, captions_embeddings, output_logits = out\n",
    "# print(captions_embeddings.shape)\n",
    "# a = output_logits.reshape(-1, len(tokenizer))\n",
    "# b = target.reshape(-1)\n",
    "# print(\"a\", a.shape, a)\n",
    "# print(\"b\", b.shape, b)\n",
    "\n",
    "# ce_loss = ce_fn(a, b)\n",
    "# print(ce_loss.shape)\n",
    "# N = len(x['images'])\n",
    "# M = len(x['qa2i'])\n",
    "# ce = ce_loss.reshape(-1, M).transpose(0, 1)\n",
    "# print(ce.shape)\n",
    "# print(ce)\n",
    "# per_qa  = torch.mean(ce, axis = 1)\n",
    "# print(per_qa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb911c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blown = models.blow_to(image_embedding, result['c2i'])\n",
    "# print(image_embedding.shape)\n",
    "# print(image_embedding)\n",
    "# print(blown.shape)\n",
    "# print(blown)\n",
    "# print(\"captions_embedding:\", captions_embeddings.shape)\n",
    "# print(result['c2i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ab542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(blown)\n",
    "# print(captions_embeddings)\n",
    "# cos= nn.CosineSimilarity(dim = 0)\n",
    "# print(cos(blown[1], captions_embeddings[1]))\n",
    "\n",
    "# per_caption_loss = cos_fn(blown, captions_embeddings)\n",
    "# print(per_caption_loss)\n",
    "# per_image_caption_loss = cal_average(len(result['images']), per_caption_loss, result['c2i'])\n",
    "# print(per_image_caption_loss.shape)\n",
    "\n",
    "# print(per_image_caption_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c60e72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload_model( lr, name):\n",
    "    model = VQANet(tokenizer).to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    if name is not None:\n",
    "        checkpoint = torch.load(constants.MODEL_OUT_PATH.joinpath(name))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return model, optimizer\n",
    "\n",
    "def save_model(model, optimizer, name):\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()},\n",
    "        constants.MODEL_OUT_PATH.joinpath(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58826949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_average(size, blown_loss, replicas):\n",
    "    result= torch.zeros(size).to(device)\n",
    "    counts = torch.zeros(size).to(device)\n",
    "    for index, val in enumerate(replicas):\n",
    "        result[val] += blown_loss[index]\n",
    "        counts[val] += 1\n",
    "        \n",
    "    for index in range(size):\n",
    "        if counts[index] == 0:\n",
    "            counts[index] = 1  # so that result / counts still makes sense.\n",
    "    #print(\"result\", result)\n",
    "    #print(\"counts:\", counts)\n",
    "    counts = counts.detach()  # we don't need gradient for the counts.\n",
    "    result /= counts\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bb76a2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gamma = 0.9\n",
    "DEBUG = False\n",
    "def do_train(model, optimizer, idx, x, target, should_print = False):\n",
    "        N = len(x['image_ids'])\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        if DEBUG:\n",
    "            image_embedding_for_captions, captions_embedding, output_logits = None, None, None\n",
    "        else:\n",
    "            image_embedding_for_captions, captions_embedding, output_logits  = model(x, device)\n",
    "\n",
    "#        image_embedding, captions_embedding, output_logits = None, None, None\n",
    "        per_image_qa_loss = None\n",
    "        per_image_caption_loss = None\n",
    "        \n",
    "        if output_logits is not None:\n",
    "#            print(\"out_logits argmax\", torch.argmax(output_logits.transpose(0,1), axis=2))\n",
    "#            print(\"target\", target)\n",
    "            a = output_logits.reshape(-1, len(tokenizer))\n",
    "\n",
    "            b = target.reshape(-1)\n",
    "#            print(\"a\", a.shape)\n",
    "#            print(\"b\", b.shape)\n",
    "\n",
    "            K = len(x['qa2i'])\n",
    "            # back to (K, seq)\n",
    "            qa_loss = ce_fn(a, b).reshape(-1, K).transpose(0, 1)\n",
    "            #print(\"qa_loss\", qa_loss.shape)\n",
    "            # qa loss, shape of (K) (different images can have diff counts of qas)\n",
    "            per_qa_loss = torch.mean(qa_loss, axis = 1)\n",
    "\n",
    "            # per image qa loss, shape of (N)\n",
    "            per_image_qa_loss = cal_average(N, per_qa_loss, x['qa2i'])\n",
    "            #print(\"per_qa_loss\", per_qa_loss.shape)\n",
    "            #print(\"per_image_qa_loss\", per_image_qa_loss.shape)\n",
    "\n",
    "        if captions_embedding is not None:\n",
    "            # loss per caption, shape of (M) (different images can have diff counts of captions)\n",
    "            per_caption_loss = cos_fn(image_embedding_for_captions, captions_embedding)\n",
    "            # cosine similarity is within [-1, 1] where 1 being similar. \n",
    "            # for loss, we invert it and shift it by 1 to keep the value always positive.\n",
    "            # thus 0 means similar, 2 means completely opposite\n",
    "            # print(\"per_captions_loss:\", per_caption_loss)\n",
    "            per_caption_loss = -per_caption_loss + 1\n",
    "            # print(\"normalized per_captions_loss:\", per_caption_loss)\n",
    "            # per image loss on the caption scale. shape of (N)\n",
    "            per_image_caption_loss = cal_average(N, per_caption_loss, x['c2i'])\n",
    "\n",
    "        total_loss = 0\n",
    "        if per_image_qa_loss is not None:\n",
    "            total_loss += gamma * per_image_caption_loss\n",
    "            \n",
    "        if per_image_qa_loss is not None:\n",
    "            total_loss += per_image_qa_loss\n",
    "\n",
    "        loss = torch.sum(total_loss)\n",
    "\n",
    "        if not DEBUG:\n",
    "            loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        del per_image_caption_loss\n",
    "        del per_image_qa_loss\n",
    "        del x\n",
    "        del total_loss\n",
    "        return loss\n",
    "            \n",
    "def training(writer, epoches, early_terminate = None, sync_after_every_n = 200, print_every = 100):\n",
    "    lr = 0.1\n",
    "    model, optimizer = reload_model(lr, None)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_name = 'train-' + datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "    \n",
    "    model.train()\n",
    "    for epoch_idx in range(epoches):\n",
    "        print (\"----- Start Epoch %s -----\" % epoch_idx)\n",
    "        epoch_loss = 0\n",
    "        for idx, (x, target) in enumerate(train_dataloader):\n",
    "            should_print = print_every is not None and (print_every == 1 or idx % (print_every -1) == 0)\n",
    "            if should_print:\n",
    "                print(\">>>> Batch # \", idx,  x['image_ids'] )\n",
    "            if early_terminate is not None:\n",
    "                if idx > early_terminate - 1:\n",
    "                    print(\"early terminating. at \", idx)\n",
    "                    break;\n",
    "            try:\n",
    "                loss = do_train(model, optimizer, idx, x, target, should_print).detach()\n",
    "                batch_loss = loss.item()\n",
    "            except Exception as e:\n",
    "                print(\">>>> FAILED! Batch # \", idx,  x['image_ids'])\n",
    "                traceback.print_exc()\n",
    "                break;\n",
    "\n",
    "            if sync_after_every_n is not None and (idx + 1) % sync_after_every_n == 0:\n",
    "                print(\"=========== mps sync, gc, and mps empty cache and reload ==========\")\n",
    "                name = model_name + f\"-epoch-{epoch_idx}-batch-{idx}\"\n",
    "                save_model(model, optimizer, name)\n",
    "                model = None\n",
    "                optimizer = None\n",
    "                torch.mps.synchronize()\n",
    "                gc.collect()\n",
    "                torch.mps.empty_cache()\n",
    "                model, optimizer = reload_model(lr, name)\n",
    "                model.train()\n",
    "\n",
    "            if should_print:\n",
    "                print(\"loss:\", batch_loss)\n",
    "                print(\"--- %s Per batch time ---\" % (time.time() - start_time))\n",
    "                \n",
    "            epoch_loss += batch_loss\n",
    "\n",
    "        epoch_loss /= len(train_dataloader) if early_terminate is None \\\n",
    "                                            else (early_terminate * train_dataloader.batch_size)\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss, epoch_idx)\n",
    "\n",
    "        print(f\"---DONE: {epoch_idx} epoch, {(time.time() - start_time)} seconds, loss {epoch_loss} ---\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11292824",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Start Epoch 0 -----\n",
      ">>>> Batch #  0 [9, 25, 30, 34, 36]\n",
      "loss: 58.73096466064453\n",
      "--- 2.011552095413208 Per batch time ---\n",
      ">>>> Batch #  1 [42, 49, 61, 64, 71]\n",
      "loss: 45.55876159667969\n",
      "--- 3.687784194946289 Per batch time ---\n",
      ">>>> Batch #  2 [72, 73, 74, 77, 78]\n",
      "loss: 33.52019500732422\n",
      "--- 5.3537609577178955 Per batch time ---\n",
      ">>>> Batch #  3 [81, 86, 89, 92, 94]\n",
      "loss: 48.776939392089844\n",
      "--- 7.022082090377808 Per batch time ---\n",
      ">>>> Batch #  4 [109, 110, 113, 127, 133]\n",
      "=========== mps sync, gc, and mps empty cache and reload ==========\n",
      "loss: 32.89650344848633\n",
      "--- 12.380654096603394 Per batch time ---\n",
      ">>>> Batch #  5 [136, 138, 142, 143, 144]\n",
      "loss: 25.630126953125\n",
      "--- 14.17305588722229 Per batch time ---\n",
      ">>>> Batch #  6 [149, 151, 154, 164, 165]\n",
      "loss: 28.86085319519043\n",
      "--- 16.017032146453857 Per batch time ---\n",
      ">>>> Batch #  7 [192, 194, 196, 201, 208]\n",
      "loss: 15.156055450439453\n",
      "--- 17.720378160476685 Per batch time ---\n",
      ">>>> Batch #  8 [241, 247, 250, 257, 260]\n",
      "loss: 21.24652862548828\n",
      "--- 19.4218852519989 Per batch time ---\n",
      ">>>> Batch #  9 [263, 283, 294, 307, 308]\n",
      "=========== mps sync, gc, and mps empty cache and reload ==========\n",
      "loss: 18.347742080688477\n",
      "--- 24.613158226013184 Per batch time ---\n",
      ">>>> Batch #  10 [309, 312, 315, 321, 322]\n",
      "early terminating. at  10\n",
      "---DONE: 0 epoch, 24.622081995010376 seconds, loss 6.574493408203125 ---\n",
      "----- Start Epoch 1 -----\n",
      ">>>> Batch #  0 [9, 25, 30, 34, 36]\n",
      "loss: 24.428146362304688\n",
      "--- 26.681631088256836 Per batch time ---\n",
      ">>>> Batch #  1 [42, 49, 61, 64, 71]\n",
      "loss: 23.3883113861084\n",
      "--- 28.511258125305176 Per batch time ---\n",
      ">>>> Batch #  2 [72, 73, 74, 77, 78]\n",
      "loss: 20.752708435058594\n",
      "--- 30.246325969696045 Per batch time ---\n",
      ">>>> Batch #  3 [81, 86, 89, 92, 94]\n",
      "loss: 27.915771484375\n",
      "--- 32.034972190856934 Per batch time ---\n",
      ">>>> Batch #  4 [109, 110, 113, 127, 133]\n",
      "=========== mps sync, gc, and mps empty cache and reload ==========\n",
      "loss: 20.941091537475586\n",
      "--- 37.364816188812256 Per batch time ---\n",
      ">>>> Batch #  5 [136, 138, 142, 143, 144]\n",
      "loss: 18.220781326293945\n",
      "--- 39.11811709403992 Per batch time ---\n",
      ">>>> Batch #  6 [149, 151, 154, 164, 165]\n",
      "loss: 19.380428314208984\n",
      "--- 40.97459030151367 Per batch time ---\n",
      ">>>> Batch #  7 [192, 194, 196, 201, 208]\n",
      "loss: 10.705305099487305\n",
      "--- 42.74372410774231 Per batch time ---\n",
      ">>>> Batch #  8 [241, 247, 250, 257, 260]\n",
      "loss: 15.611433982849121\n",
      "--- 44.47479009628296 Per batch time ---\n",
      ">>>> Batch #  9 [263, 283, 294, 307, 308]\n",
      "=========== mps sync, gc, and mps empty cache and reload ==========\n",
      "loss: 13.84101676940918\n",
      "--- 49.83903217315674 Per batch time ---\n",
      ">>>> Batch #  10 [309, 312, 315, 321, 322]\n",
      "early terminating. at  10\n",
      "---DONE: 1 epoch, 49.846243143081665 seconds, loss 3.903699893951416 ---\n",
      "----- Start Epoch 2 -----\n",
      ">>>> Batch #  0 [9, 25, 30, 34, 36]\n",
      "loss: 17.85982894897461\n",
      "--- 51.911962032318115 Per batch time ---\n",
      ">>>> Batch #  1 [42, 49, 61, 64, 71]\n",
      "loss: 17.079509735107422\n",
      "--- 53.706347942352295 Per batch time ---\n",
      ">>>> Batch #  2 [72, 73, 74, 77, 78]\n",
      "loss: 15.506793975830078\n",
      "--- 55.44807696342468 Per batch time ---\n",
      ">>>> Batch #  3 [81, 86, 89, 92, 94]\n",
      "loss: 20.78675079345703\n",
      "--- 57.237173080444336 Per batch time ---\n",
      ">>>> Batch #  4 [109, 110, 113, 127, 133]\n",
      "=========== mps sync, gc, and mps empty cache and reload ==========\n",
      "loss: 15.234408378601074\n",
      "--- 62.57554006576538 Per batch time ---\n",
      ">>>> Batch #  5 [136, 138, 142, 143, 144]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "current_time = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "writer = SummaryWriter(Path.joinpath(constants.TB_OUT_PATH, \"with_sync_\" + current_time))\n",
    "\n",
    "model = training(writer, 5, sync_after_every_n=5, print_every = 1,  early_terminate = 10)\n",
    "writer.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "024d74c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Start Epoch 0 -----\n",
      ">>>> Batch #  0 [9, 25, 30, 34, 36]\n",
      "loss: 56.32360076904297\n",
      "--- 2.0319719314575195 Per batch time ---\n",
      ">>>> Batch #  1 [42, 49, 61, 64, 71]\n",
      "loss: 44.15825271606445\n",
      "--- 3.8284220695495605 Per batch time ---\n",
      ">>>> Batch #  2 [72, 73, 74, 77, 78]\n",
      "loss: 32.260902404785156\n",
      "--- 5.541014194488525 Per batch time ---\n",
      ">>>> Batch #  3 [81, 86, 89, 92, 94]\n",
      "loss: 47.25675964355469\n",
      "--- 7.24758505821228 Per batch time ---\n",
      ">>>> Batch #  4 [109, 110, 113, 127, 133]\n",
      "loss: 31.200536727905273\n",
      "--- 8.984709978103638 Per batch time ---\n",
      ">>>> Batch #  5 [136, 138, 142, 143, 144]\n",
      "loss: 25.550800323486328\n",
      "--- 10.736034154891968 Per batch time ---\n",
      ">>>> Batch #  6 [149, 151, 154, 164, 165]\n",
      "loss: 28.784555435180664\n",
      "--- 12.54118800163269 Per batch time ---\n",
      ">>>> Batch #  7 [192, 194, 196, 201, 208]\n",
      "loss: 14.63433837890625\n",
      "--- 14.258178949356079 Per batch time ---\n",
      ">>>> Batch #  8 [241, 247, 250, 257, 260]\n",
      "loss: 21.023765563964844\n",
      "--- 15.991867065429688 Per batch time ---\n",
      ">>>> Batch #  9 [263, 283, 294, 307, 308]\n",
      "loss: 17.431005477905273\n",
      "--- 17.731816053390503 Per batch time ---\n",
      ">>>> Batch #  10 [309, 312, 315, 321, 322]\n",
      "early terminating. at  10\n",
      "---DONE: 0 epoch, 17.738952159881592 seconds, loss 6.372490348815918 ---\n",
      "----- Start Epoch 1 -----\n",
      ">>>> Batch #  0 [9, 25, 30, 34, 36]\n",
      "loss: 23.27402114868164\n",
      "--- 19.809421062469482 Per batch time ---\n",
      ">>>> Batch #  1 [42, 49, 61, 64, 71]\n",
      "loss: 21.727558135986328\n",
      "--- 21.574172019958496 Per batch time ---\n",
      ">>>> Batch #  2 [72, 73, 74, 77, 78]\n",
      "loss: 18.930034637451172\n",
      "--- 23.28738498687744 Per batch time ---\n",
      ">>>> Batch #  3 [81, 86, 89, 92, 94]\n",
      "loss: 26.457408905029297\n",
      "--- 25.02621817588806 Per batch time ---\n",
      ">>>> Batch #  4 [109, 110, 113, 127, 133]\n",
      "loss: 18.63899040222168\n",
      "--- 26.77895998954773 Per batch time ---\n",
      ">>>> Batch #  5 [136, 138, 142, 143, 144]\n",
      "loss: 15.625102043151855\n",
      "--- 28.50272488594055 Per batch time ---\n",
      ">>>> Batch #  6 [149, 151, 154, 164, 165]\n",
      "loss: 17.01654815673828\n",
      "--- 30.3316330909729 Per batch time ---\n",
      ">>>> Batch #  7 [192, 194, 196, 201, 208]\n",
      "loss: 10.472838401794434\n",
      "--- 32.01606202125549 Per batch time ---\n",
      ">>>> Batch #  8 [241, 247, 250, 257, 260]\n",
      "loss: 14.361565589904785\n",
      "--- 33.73674416542053 Per batch time ---\n",
      ">>>> Batch #  9 [263, 283, 294, 307, 308]\n",
      "loss: 12.451188087463379\n",
      "--- 35.43242907524109 Per batch time ---\n",
      ">>>> Batch #  10 [309, 312, 315, 321, 322]\n",
      "early terminating. at  10\n",
      "---DONE: 1 epoch, 35.439531087875366 seconds, loss 3.5791051101684572 ---\n",
      "----- Start Epoch 2 -----\n",
      ">>>> Batch #  0 [9, 25, 30, 34, 36]\n",
      "loss: 16.53696060180664\n",
      "--- 37.436097145080566 Per batch time ---\n",
      ">>>> Batch #  1 [42, 49, 61, 64, 71]\n",
      "loss: 16.12896728515625\n",
      "--- 39.16051697731018 Per batch time ---\n",
      ">>>> Batch #  2 [72, 73, 74, 77, 78]\n",
      "loss: 14.484187126159668\n",
      "--- 40.8244891166687 Per batch time ---\n",
      ">>>> Batch #  3 [81, 86, 89, 92, 94]\n",
      "loss: 19.32082748413086\n",
      "--- 42.50939917564392 Per batch time ---\n",
      ">>>> Batch #  4 [109, 110, 113, 127, 133]\n",
      "loss: 14.124597549438477\n",
      "--- 44.25694298744202 Per batch time ---\n",
      ">>>> Batch #  5 [136, 138, 142, 143, 144]\n",
      "loss: 12.109672546386719\n",
      "--- 45.91267204284668 Per batch time ---\n",
      ">>>> Batch #  6 [149, 151, 154, 164, 165]\n",
      "loss: 13.232248306274414\n",
      "--- 47.69336295127869 Per batch time ---\n",
      ">>>> Batch #  7 [192, 194, 196, 201, 208]\n",
      "loss: 8.446247100830078\n",
      "--- 49.4192910194397 Per batch time ---\n",
      ">>>> Batch #  8 [241, 247, 250, 257, 260]\n",
      "loss: 11.94761848449707\n",
      "--- 51.12258219718933 Per batch time ---\n",
      ">>>> Batch #  9 [263, 283, 294, 307, 308]\n",
      "loss: 10.665099143981934\n",
      "--- 52.80494022369385 Per batch time ---\n",
      ">>>> Batch #  10 [309, 312, 315, 321, 322]\n",
      "early terminating. at  10\n",
      "---DONE: 2 epoch, 52.81189203262329 seconds, loss 2.739928512573242 ---\n",
      "----- Start Epoch 3 -----\n",
      ">>>> Batch #  0 [9, 25, 30, 34, 36]\n",
      "loss: 13.952153205871582\n",
      "--- 54.78625798225403 Per batch time ---\n",
      ">>>> Batch #  1 [42, 49, 61, 64, 71]\n",
      "loss: 13.227912902832031\n",
      "--- 56.51617217063904 Per batch time ---\n",
      ">>>> Batch #  2 [72, 73, 74, 77, 78]\n",
      "loss: 12.145233154296875\n",
      "--- 58.209636926651 Per batch time ---\n",
      ">>>> Batch #  3 [81, 86, 89, 92, 94]\n",
      "loss: 15.955037117004395\n",
      "--- 59.9280731678009 Per batch time ---\n",
      ">>>> Batch #  4 [109, 110, 113, 127, 133]\n",
      "loss: 11.871565818786621\n",
      "--- 61.6665301322937 Per batch time ---\n",
      ">>>> Batch #  5 [136, 138, 142, 143, 144]\n",
      "loss: 9.949951171875\n",
      "--- 63.28809905052185 Per batch time ---\n",
      ">>>> Batch #  6 [149, 151, 154, 164, 165]\n",
      "loss: 11.290152549743652\n",
      "--- 65.11112999916077 Per batch time ---\n",
      ">>>> Batch #  7 [192, 194, 196, 201, 208]\n",
      "loss: 7.193933486938477\n",
      "--- 66.82704496383667 Per batch time ---\n",
      ">>>> Batch #  8 [241, 247, 250, 257, 260]\n",
      "loss: 10.379305839538574\n",
      "--- 68.71521019935608 Per batch time ---\n",
      ">>>> Batch #  9 [263, 283, 294, 307, 308]\n",
      "loss: 9.211503982543945\n",
      "--- 70.40019702911377 Per batch time ---\n",
      ">>>> Batch #  10 [309, 312, 315, 321, 322]\n",
      "early terminating. at  10\n",
      "---DONE: 3 epoch, 70.40718603134155 seconds, loss 2.303534984588623 ---\n",
      "----- Start Epoch 4 -----\n",
      ">>>> Batch #  0 [9, 25, 30, 34, 36]\n",
      "loss: 12.378525733947754\n",
      "--- 72.4108829498291 Per batch time ---\n",
      ">>>> Batch #  1 [42, 49, 61, 64, 71]\n",
      "loss: 11.677786827087402\n",
      "--- 74.15906596183777 Per batch time ---\n",
      ">>>> Batch #  2 [72, 73, 74, 77, 78]\n",
      "loss: 10.4379301071167\n",
      "--- 75.79598808288574 Per batch time ---\n",
      ">>>> Batch #  3 [81, 86, 89, 92, 94]\n",
      "loss: 14.176379203796387\n",
      "--- 77.5115978717804 Per batch time ---\n",
      ">>>> Batch #  4 [109, 110, 113, 127, 133]\n",
      "loss: 11.072851181030273\n",
      "--- 79.26287388801575 Per batch time ---\n",
      ">>>> Batch #  5 [136, 138, 142, 143, 144]\n",
      "loss: 8.540597915649414\n",
      "--- 80.9439172744751 Per batch time ---\n",
      ">>>> Batch #  6 [149, 151, 154, 164, 165]\n",
      "loss: 10.500287055969238\n",
      "--- 82.74940514564514 Per batch time ---\n",
      ">>>> Batch #  7 [192, 194, 196, 201, 208]\n",
      "loss: 6.74957275390625\n",
      "--- 84.45629096031189 Per batch time ---\n",
      ">>>> Batch #  8 [241, 247, 250, 257, 260]\n",
      "loss: 9.498279571533203\n",
      "--- 86.14956188201904 Per batch time ---\n",
      ">>>> Batch #  9 [263, 283, 294, 307, 308]\n",
      "loss: 8.337374687194824\n",
      "--- 87.85667896270752 Per batch time ---\n",
      ">>>> Batch #  10 [309, 312, 315, 321, 322]\n",
      "early terminating. at  10\n",
      "---DONE: 4 epoch, 87.86363983154297 seconds, loss 2.0673917007446287 ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_time = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "writer = SummaryWriter(Path.joinpath(constants.TB_OUT_PATH, current_time))\n",
    "\n",
    "#training(model, writer, 5, empty_catch_after_every_n=None, early_terminate = 10)\n",
    "model = training(writer, 5, sync_after_every_n=None, print_every = 1, early_terminate = 10)\n",
    "#training(model, writer, 2, empty_catch_after_every_n=None)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39f2ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa4223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def manual(dataset, size):\n",
    "    items = []\n",
    "    \n",
    "    for i in range(size):\n",
    "        item = dataset.__getitem__(i)\n",
    "        # replace the `qa` with just the `qs`\n",
    "        print(item.annotations['qa'])\n",
    "        item.annotations['qa'] = item.annotations['qs']\n",
    "        items.append(item)\n",
    "    return collate_fn2(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd6777b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\">>> original qa\")\n",
    "test1x, target = manual(val, 5)\n",
    "model.eval()\n",
    "answers = model.answer(test1x, device, max_length = 30)\n",
    "\n",
    "print(\">>> prediction\")\n",
    "def token_to_word(x):\n",
    "    qa = x[\"qa\"]\n",
    "    return tokenizer.batch_decode(qa)\n",
    "\n",
    "token_to_word(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738346e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_answers(x):\n",
    "    qa = x[\"qa\"]\n",
    "    answer_token_id = tokenizer.convert_tokens_to_ids(constants.ANSWER_TOKEN)\n",
    "\n",
    "    answer_start =  (qa == answer_token_id).nonzero()\n",
    "    mask = torch.zeros_like(qa)\n",
    "    mask[answer_start[:, 0], answer_start[:, 1]] = 1\n",
    "    # fill the elements after the [ANSWER] token to be 1.\n",
    "    mask = mask.cumsum(dim=1)\n",
    "    just_answers = qa * mask\n",
    "    return tokenizer.batch_decode(just_answers, skip_special_tokens = True)\n",
    "    \n",
    "real_answers = get_answers(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73edc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output(x, answers, result):\n",
    "    qids = x['qids']\n",
    "    assert len(qids) == len(answers)\n",
    "    for i in range(len(qids)):\n",
    "        d = {\"question_id\" : qids[i], \"answer\": answers[i]}\n",
    "        result.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "create_output(test1x, real_answers, result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140e5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.questions.loc[val.questions['question_id'] == 139001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be856f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
